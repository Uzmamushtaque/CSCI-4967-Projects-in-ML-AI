{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMN7vs50vH/0yzDfiTs80V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI-4967-Projects-in-ML-AI/blob/main/Lecture_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 23\n",
        "\n",
        "### Topics for Today\n",
        "\n",
        "1. Introduction to Diffusion Models\n",
        "2. Architecture\n",
        "3. Training"
      ],
      "metadata": {
        "id": "JsK20zw5UHZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Diffusion Models are generative models, meaning that they are used to generate data similar to the data on which they are trained. Fundamentally, Diffusion Models work by destroying training data through the successive addition of Gaussian noise, and then learning to recover the data by reversing this noising process. After training, we can use the Diffusion Model to generate data by simply passing randomly sampled noise through the learned denoising process.\n",
        "\n",
        "A diffusion model consists of an encoder and a decoder. The encoder takes a data\n",
        "sample x and maps it through a series of intermediate latent variables z1 . . . zT . The\n",
        "decoder reverses this process; it starts with zT and maps back through zT−1, . . . , z1 until\n",
        "it finally (re-)creates a data point x. In both encoder and decoder, the mappings are\n",
        "stochastic rather than deterministic.\n",
        "\n",
        "The encoder gradually blends the input with samples of white noise. With enough steps, the conditional distribution q(zT |x) and marginal distribution\n",
        "q(zT ) of the final latent variable both become the standard normal distribution.\n",
        "Since this process is prespecified, all the learned parameters are in the decoder.\n",
        "\n",
        "The decoder is a single (or a series) of networks that maps back adjacent pair of latent variables to reconstruct the input x.\n",
        "The goal of training a diffusion model is to learn the reverse process"
      ],
      "metadata": {
        "id": "96XfRgz5aEvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder (The forward process)\n",
        "\n",
        "The diffusion or forward process1  maps a data example x through a series\n",
        "of intermediate variables z1, z2, . . . , zT with the same size as x."
      ],
      "metadata": {
        "id": "Z__AlhS6bUvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diffusion Kernel\n",
        "\n",
        "To train the decoder to invert this process, we use multiple samples zt at time t for the\n",
        "same example x. However, generating these sequentially is timeconsuming\n",
        "when t is large. Fortunately, there is a closed-form expression for q(zt|x),\n",
        "which allows us to directly draw samples zt given initial data point x without computing\n",
        "the intermediate variables z1 . . . zt−1. This is known as the diffusion kernel."
      ],
      "metadata": {
        "id": "GMWMV_KPkJjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder (The backward process)\n",
        "When we learn a diffusion model, we learn the reverse process. In other words, we learn a\n",
        "series of probabilistic mappings back from latent variable zT to zT−1, from zT−1 to zT−2,\n",
        "and so on, until we reach the data x. The true reverse distributions q(zt−1|zt) of the\n",
        "diffusion process are complex multi-modal distributions that depend on the\n",
        "data distribution Pr(x). We approximate these as normal distributions."
      ],
      "metadata": {
        "id": "93WgD85jkL14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "A Diffusion Model is trained by finding the reverse Markov transitions that maximize the likelihood of the training data. In practice, training equivalently consists of minimizing the variational upper bound on the negative log likelihood.\n",
        "\n",
        "[Source](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)"
      ],
      "metadata": {
        "id": "vrvfdZepRRHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Training](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)"
      ],
      "metadata": {
        "id": "FEtC6BjfRTwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stable diffusion\n",
        "\n",
        "Stable Diffusion is a generative artificial intelligence (generative AI) model that produces unique photorealistic images from text and image prompts. It originally launched in 2022. Besides images, you can also use the model to create videos and animations. The model is based on diffusion technology and uses latent space. This significantly reduces processing requirements, and you can run the model on desktops or laptops equipped with GPUs. Stable Diffusion can be fine-tuned to meet your specific needs with as little as five images through transfer learning.\n",
        "\n",
        "[Source](https://aws.amazon.com/what-is/stable-diffusion/)"
      ],
      "metadata": {
        "id": "ilK2hHhbUpOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Research\n",
        "\n",
        "[Stable diffusion](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)\n",
        "\n",
        "[Comparative study](https://arxiv.org/pdf/2210.00586.pdf)"
      ],
      "metadata": {
        "id": "cfYaz7ulkOV_"
      }
    }
  ]
}